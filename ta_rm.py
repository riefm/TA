# -*- coding: utf-8 -*-
"""TA_RM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bi4zJ1pzR8iYr5ldeilVbZzGVv7qdfFG
"""

import numpy as np
import pandas as pd
import re
import string
import nltk

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

df = pd.read_csv('data_pertanyaan (2).csv', sep=';')
df.head()

# melihat jumlah baris dan kolom
df.shape

df['Reaksi sistem'].value_counts()

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

#merubah teks jadi huruf kecil
df['Pertanyaan'] = df['Pertanyaan'].str.lower()

#remove symbols
df['Pertanyaan'] = df['Pertanyaan'].str.replace("\'\?\!",'', case=False)

#remove punc
df['Pertanyaan'] = df['Pertanyaan'].str.replace('[^\w\s]','', case=False)

df.Pertanyaan.head()

#tokenizing
from nltk.tokenize import word_tokenize

x = df.iloc[0]
print(nltk.word_tokenize(x['Pertanyaan']))

def identify_tokens(row):
  message = row['Pertanyaan']
  tokens = nltk.word_tokenize(message)
  token_words = [w for w in tokens if w.isalpha()]
  return token_words

df['Pertanyaan'] = df.apply(identify_tokens, axis = 1)
df.Pertanyaan.head()

#stopword
from nltk.corpus import stopwords

stops = set(stopwords.words('indonesian'))

def remove_stops(row):
  message = row['Pertanyaan']
  stopwords = [w for w in message if not w in stops]
  return stopwords

df['Pertanyaan'] = df.apply(remove_stops, axis = 1)
df['Pertanyaan'] = df['Pertanyaan'].str.join(" ")
df.Pertanyaan.head()

#menampilkan wordcloud keseluruhan
from wordcloud import WordCloud
import matplotlib.pyplot as plt

all_text= ' '.join(word for word in df['Pertanyaan'])
wordcloud = WordCloud(width = 1000, mode = 'RGBA', background_color = 'white').generate(all_text)
plt.figure(figsize = (20,10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.margins(x=0, y=0)
plt.show

df.head()

#TF-IDF
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
tfidf = vectorizer.fit_transform(df['Pertanyaan'])
vectorizer.get_feature_names_out()
tfidf.toarray()

tfidf

from sklearn.model_selection import train_test_split
x = df['Pertanyaan']
y = df['Reaksi sistem']
x_train, x_test, y_train, y_test, = train_test_split(x, y, test_size = 0.3)

x

y

# vectorisasi
from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()
vectorizer.fit(x_train)

x_train = vectorizer.transform(x_train)
x_test = vectorizer.transform(x_test)

print(x_train.shape)
print(x_test.shape)

x_train

(x_train.toarray())

#SVM
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score
for c in [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]:
  svm = LinearSVC(C=c)
  svm.fit(x_train, y_train)
  print('Akurasi untuk C = %s: %s' %(c, accuracy_score(y_test, svm.predict(x_test))))

svm = LinearSVC(C = 1) # Cari C yang akurasinya paling besar
svm.fit(x_train, y_train)

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

y_predd = svm.predict(x_test)
print('Akurasi of SVM classifier on test set: {:.4f}'.format(svm.score(x_test, y_test)))
print(classification_report(y_test, y_predd))

from sklearn.metrics import confusion_matrix
import seaborn as sns
cf_matrix = confusion_matrix(y_test, y_predd)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)

ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')

ax.set_title('SVM Confusion Matrix \n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['Sesuai','Tidak Sesuai'])
ax.yaxis.set_ticklabels(['Sesuai','Tidak Sesuai'])

## Display the visualization of the Confusion Matrix.
plt.show()

from sklearn import svm, datasets
import sklearn.model_selection as model_selection
from sklearn.metrics import accuracy_score

poly = svm.SVC(kernel='poly', degree=2, C=10).fit(x_train, y_train)
rbf = svm.SVC(kernel='rbf', gamma=0.1, C=1).fit(x_train, y_train)

poly_pred = poly.predict(x_test)
rbf_pred = rbf.predict(x_test)

from sklearn.metrics import classification_report

print('Accuracy (Polynomial Kernel): {:.4f}'.format(poly.score(x_test, y_test)))
print(classification_report(y_test, poly_pred))

print()

from sklearn.metrics import confusion_matrix
import seaborn as sns
cf_matrix = confusion_matrix(y_test, poly_pred)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)

ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')

ax.set_title('SVM Confusion Matrix \n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['Sesuai','Tidak Sesuai'])
ax.yaxis.set_ticklabels(['Sesuai','Tidak Sesuai'])

## Display the visualization of the Confusion Matrix.
plt.show()

from sklearn.metrics import classification_report

print('Accuracy (RBF Kernel): {:.4f}'.format(rbf.score(x_test, y_test)))
print(classification_report(y_test, rbf_pred))

from sklearn.metrics import confusion_matrix
import seaborn as sns
cf_matrix = confusion_matrix(y_test, rbf_pred)

group_names = ['True Neg','False Pos','False Neg','True Pos']
group_counts = ["{0:0.0f}".format(value) for value in
                cf_matrix.flatten()]
group_percentages = ["{0:.2%}".format(value) for value in
                     cf_matrix.flatten()/np.sum(cf_matrix)]
labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
          zip(group_names,group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)

ax = sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')

ax.set_title('SVM Confusion Matrix \n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['Sesuai','Tidak Sesuai'])
ax.yaxis.set_ticklabels(['Sesuai','Tidak Sesuai'])

## Display the visualization of the Confusion Matrix.
plt.show()

from sklearn.model_selection import GridSearchCV
parameters = {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000],
              'degree': [2, 3, 4, 5],
              'gamma':[0.001, 0.01, 0.1, 0.5, 1],
              'kernel': ['rbf']
              }        
cl = svm.SVC()
grid = GridSearchCV(cl, parameters, cv=10)
grid.fit(x_train, y_train)
print(grid.best_params_)
print(grid.best_estimator_)

from sklearn.model_selection import GridSearchCV
parameters = {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000],
              'degree': [2, 3, 4, 5],
              'gamma':[0.001, 0.01, 0.1, 0.5, 1],
              'kernel': ['poly']
              }        
cl = svm.SVC()
grid = GridSearchCV(cl, parameters, cv=10)
grid.fit(x_train, y_train)
print(grid.best_params_)
print(grid.best_estimator_)

from sklearn.metrics import confusion_matrix
import seaborn as sns

cf_matrix = confusion_matrix(y_test, y_predd)
ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')

ax.set_title('Confusion Matrix \n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['Kediri','Prodamas'])
ax.yaxis.set_ticklabels(['Kediri','Prodamas'])

## Display the visualization of the Confusion Matrix.
plt.show()

"""---"""